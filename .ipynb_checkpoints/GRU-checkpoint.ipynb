{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "#preprocessing\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#performance metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#keras packages\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mafalda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mafalda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                  short_description  \n",
       "0  Melissa Jeltsen  She left her husband. He killed their children...  \n",
       "1    Andy McDonald                           Of course it has a song.  \n",
       "2       Ron Dicker  The actor and his longtime girlfriend Anna Ebe...  \n",
       "3       Ron Dicker  The actor gives Dems an ass-kicking for not fi...  \n",
       "4       Ron Dicker  The \"Dietland\" actress said using the bags is ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "df = pd.read_json('News_Category_Dataset_v2.json', lines = True)\n",
    "\n",
    "df = df.drop(['link', 'date'], axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>short_description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                  short_description  \\\n",
       "0  Melissa Jeltsen  She left her husband. He killed their children...   \n",
       "1    Andy McDonald                           Of course it has a song.   \n",
       "2       Ron Dicker  The actor and his longtime girlfriend Anna Ebe...   \n",
       "3       Ron Dicker  The actor gives Dems an ass-kicking for not fi...   \n",
       "4       Ron Dicker  The \"Dietland\" actress said using the bags is ...   \n",
       "\n",
       "                                                text  \n",
       "0  There Were 2 Mass Shootings In Texas Last Week...  \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...  \n",
       "2  Hugh Grant Marries For The First Time At Age 5...  \n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...  \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['headline'] + df['short_description']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe,punctuation=False,tags=False,stemming=False,lemmatizing=False,stopWords=False,\n",
    "                  lowercasing=False,accents=False):\n",
    "    \"\"\"\n",
    "    Function that receives a Pandas DataFrame with the texts and applies\n",
    "        the chosen preprocessing techiniques.\n",
    "        \n",
    "    :param dataframe: a Pandas DataFrame in which the first column \n",
    "        contains the estracted texts the second column contains the\n",
    "        respective authors\n",
    "    :param punctuation: bool determining whether or remove punctuation\n",
    "        and numbers or not (default: False)\n",
    "    :param tags: bool determining whether to remove tags or not\n",
    "        (default: False)\n",
    "    :param stemming: bool determining whether to perform stemming or not\n",
    "        (default: False)\n",
    "    :param lemmatizing: bool determining whether to perform lemmatizing \n",
    "        or not (default: False)\n",
    "             \n",
    "    :return: Returns a list of strings which correspond to each text after\n",
    "        preprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_corpus = []\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # for each text in the Pandas DataFrame\n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = dataframe[i]\n",
    "                \n",
    "        # remove punctuation\n",
    "        if punctuation:\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "        # remove tags\n",
    "        if tags:\n",
    "            text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        # convert to list from str\n",
    "        text = text.split()\n",
    "\n",
    "        # stemming\n",
    "        if stemming:\n",
    "            stemmer = SnowballStemmer('english')\n",
    "            \n",
    "            # don't stem stop words so that they can still be detected\n",
    "            text = [stemmer.stem(word) for word in text if not word in stop_words]\n",
    "        \n",
    "        # lemmatization\n",
    "        if lemmatizing:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            \n",
    "            text = [lemmatizer.lemmatize(word) for word in text if not word in stop_words]\n",
    "        \n",
    "        # removing stop words\n",
    "        if stopWords:\n",
    "            text = [word for word in text if not word in stop_words]\n",
    "        \n",
    "        # convert to str from list\n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        # lowecase the text\n",
    "        if lowercasing:\n",
    "            text = text.lower()\n",
    "        \n",
    "        # remove accents\n",
    "        if accents:\n",
    "            text = unidecode(text)\n",
    "\n",
    "        # save the preprocessed text on a list\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5a81161fe544b480f76f00f0e72a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200853.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess the text and save it in a Pandas Series\n",
    "cleaned_text = preprocessing(\n",
    "    df['text'],\n",
    "    punctuation=True,\n",
    "    #tags=True,\n",
    "    #stemming=True,\n",
    "    #lemmatizing=True,\n",
    "    #stopWords=True,\n",
    "    #lowercasing=True,\n",
    "    #accents=True\n",
    ")\n",
    "df['clean_text'] = pd.Series(cleaned_text, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>short_description</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>There Were Mass Shootings In Texas Last Week B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Jim Carrey Blasts Castrato Adam Schiff And Dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                  short_description  \\\n",
       "0  Melissa Jeltsen  She left her husband. He killed their children...   \n",
       "1    Andy McDonald                           Of course it has a song.   \n",
       "2       Ron Dicker  The actor and his longtime girlfriend Anna Ebe...   \n",
       "3       Ron Dicker  The actor gives Dems an ass-kicking for not fi...   \n",
       "4       Ron Dicker  The \"Dietland\" actress said using the bags is ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  Hugh Grant Marries For The First Time At Age 5...   \n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  There Were Mass Shootings In Texas Last Week B...  \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The W...  \n",
       "2  Hugh Grant Marries For The First Time At Age T...  \n",
       "3  Jim Carrey Blasts Castrato Adam Schiff And Dem...  \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['clean_text']\n",
    "target = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary_size = 20000\n",
    "vocabulary_size = 15000\n",
    "tokenizer = text.Tokenizer(num_words = vocabulary_size)\n",
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "len_sequences = [len(x) for x in sequences]\n",
    "max_len = max(len_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sequence.pad_sequences(sequences, maxlen=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X,y_train,y = train_test_split(data,target,test_size=0.4,shuffle=True,stratify=target,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,X_test,y_val,y_test = train_test_split(X,y,test_size=0.5,shuffle=True,stratify=y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "#X_val = X_val.reshape((X_val.shape[0],X_val.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120511, 150)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.reshape((120511,1))\n",
    "y_val = y_val.values.reshape((40171,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = enc.fit_transform(y_train)\n",
    "y_val = enc.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(nodes=64,optimizer='rmsprop',loss='categorical_crossentropy'):\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(2)\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(vocabulary_size, nodes, input_length=150))\n",
    "    model.add(layers.GRU(nodes,\n",
    "                         #dropout=0.5,\n",
    "                         #recurrent_dropout=0.5,\n",
    "                         input_shape=(None,X_train.shape[-1]),\n",
    "                         #return_sequences=True\n",
    "                        ))\n",
    "    model.add(layers.Dense(41, activation='softmax'))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor = 'val_accuracy',\n",
    "        patience = 1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath = 'gru.h5',\n",
    "        monitor = 'val_accuracy',\n",
    "        save_best_only = True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120511 samples, validate on 40171 samples\n",
      "Epoch 1/100\n",
      "120511/120511 [==============================] - 278s 2ms/step - loss: 3.0562 - accuracy: 0.2045 - val_loss: 2.6870 - val_accuracy: 0.2828\n",
      "Epoch 2/100\n",
      "120511/120511 [==============================] - 337s 3ms/step - loss: 2.4464 - accuracy: 0.3565 - val_loss: 2.2441 - val_accuracy: 0.4228\n",
      "Epoch 3/100\n",
      "120511/120511 [==============================] - 386s 3ms/step - loss: 1.9889 - accuracy: 0.4817 - val_loss: 1.9150 - val_accuracy: 0.5055\n",
      "Epoch 4/100\n",
      "120511/120511 [==============================] - 374s 3ms/step - loss: 1.6954 - accuracy: 0.5543 - val_loss: 1.7455 - val_accuracy: 0.5425\n",
      "Epoch 5/100\n",
      "120511/120511 [==============================] - 361s 3ms/step - loss: 1.5317 - accuracy: 0.5898 - val_loss: 1.6701 - val_accuracy: 0.5610\n",
      "Epoch 6/100\n",
      "120511/120511 [==============================] - 368s 3ms/step - loss: 1.4198 - accuracy: 0.6175 - val_loss: 1.6287 - val_accuracy: 0.5721\n",
      "Epoch 7/100\n",
      "120511/120511 [==============================] - 332s 3ms/step - loss: 1.3303 - accuracy: 0.6390 - val_loss: 1.5895 - val_accuracy: 0.5819\n",
      "Epoch 8/100\n",
      "120511/120511 [==============================] - 353s 3ms/step - loss: 1.2513 - accuracy: 0.6570 - val_loss: 1.5817 - val_accuracy: 0.5859\n",
      "Epoch 9/100\n",
      "120511/120511 [==============================] - 385s 3ms/step - loss: 1.1818 - accuracy: 0.6758 - val_loss: 1.5658 - val_accuracy: 0.5882\n",
      "Epoch 10/100\n",
      "120511/120511 [==============================] - 373s 3ms/step - loss: 1.1190 - accuracy: 0.6909 - val_loss: 1.5675 - val_accuracy: 0.5869\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=100,batch_size=256,callbacks=callbacks_list,validation_data=(X_val,y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
